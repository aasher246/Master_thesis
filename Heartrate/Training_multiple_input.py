from keras.layers import Input, Dense, LSTM, Conv1D, GlobalMaxPooling1D, Concatenate, Addfrom keras.models import Modelfrom tensorflow.keras.preprocessing.text import Tokenizerfrom keras.preprocessing.sequence import pad_sequencesfrom keras.utils import to_categoricalimport numpy as npimport tensorflow as tfnum_samples = 5000diagnosis_class_count = New.unique_diagnoses_countdiagnosis = New.diagnosispatients = New.all_dictecg_signals = New.all_ecgall_gender = New.sexnum_features = 15# Initialize a tokenizer for diagnosestokenizer = Tokenizer()# Lists to store patient inputs and labelspatient_inputs = []encoded_diagnoses = []# Lists to store sequences for paddingamplitudes_p_sequences = []amplitudes_q_sequences = []amplitudes_r_sequences = []amplitudes_s_sequences = []amplitudes_t_sequences = []pr_intervals_sequences = []pr_segments_sequences = []qrs_intervals_sequences = []qt_intervals_sequences = []rr_intervals_sequences = []st_intervals_sequences = []st_segments_sequences = []heartrate_sequences = []age_sequences = []gender_sequences = []max_sequence_length = 40  # Set this to the maximum number of featuresgender_mapping = {"Male": 0, "Female": 1}encoded_gender = [gender_mapping[gender] for gender in all_gender]for patient_data, gen in zip(patients, encoded_gender):    amplitudes_p = np.array(patient_data["Amplitudes_P"])    amplitudes_q = np.array(patient_data["Amplitudes_Q"])    amplitudes_r = np.array(patient_data["Amplitudes_R"])    amplitudes_s = np.array(patient_data["Amplitudes_S"])    amplitudes_t = np.array(patient_data["Amplitudes_T"])    pr_intervals = np.array(patient_data["PR_Intervals"])    pr_segments = np.array(patient_data["PR_Segments"])    qrs_intervals = np.array(patient_data["QRS_Intervals"])    qt_intervals = np.array(patient_data["QT_Intervals"])    rr_intervals = np.array(patient_data["RR_Intervals"])    st_intervals = np.array(patient_data["ST_Intervals"])    st_segments = np.array(patient_data["ST_Segments"])    age = np.array([int(patient_data["Age"])])    heartrate = np.array(patient_data["Heart_Rate"])    # Pad the sequences to the maximum length    amplitudes_p_sequence = pad_sequences([amplitudes_p], maxlen=max_sequence_length, dtype='float32', padding='post')    amplitudes_q_sequence = pad_sequences([amplitudes_q], maxlen=max_sequence_length, dtype='float32', padding='post')    amplitudes_r_sequence = pad_sequences([amplitudes_r], maxlen=max_sequence_length, dtype='float32', padding='post')    amplitudes_s_sequence = pad_sequences([amplitudes_s], maxlen=max_sequence_length, dtype='float32', padding='post')    amplitudes_t_sequence = pad_sequences([amplitudes_t], maxlen=max_sequence_length, dtype='float32', padding='post')    pr_intervals_sequence = pad_sequences([pr_intervals], maxlen=max_sequence_length, dtype='float32', padding='post')    pr_segments_sequence = pad_sequences([pr_segments], maxlen=max_sequence_length, dtype='float32', padding='post')    qrs_intervals_sequence = pad_sequences([qrs_intervals], maxlen=max_sequence_length, dtype='float32', padding='post')    qt_intervals_sequence = pad_sequences([qt_intervals], maxlen=max_sequence_length, dtype='float32', padding='post')    rr_intervals_sequence = pad_sequences([rr_intervals], maxlen=max_sequence_length, dtype='float32', padding='post')    st_intervals_sequence = pad_sequences([st_intervals], maxlen=max_sequence_length, dtype='float32', padding='post')    st_segments_sequence = pad_sequences([st_segments], maxlen=max_sequence_length, dtype='float32', padding='post')    # Append the padded sequences to the respective lists    amplitudes_p_sequences.append(amplitudes_p_sequence)    amplitudes_q_sequences.append(amplitudes_q_sequence)    amplitudes_r_sequences.append(amplitudes_r_sequence)    amplitudes_s_sequences.append(amplitudes_s_sequence)    amplitudes_t_sequences.append(amplitudes_t_sequence)    pr_intervals_sequences.append(pr_intervals_sequence)    pr_segments_sequences.append(pr_segments_sequence)    qrs_intervals_sequences.append(qrs_intervals_sequence)    qt_intervals_sequences.append(qt_intervals_sequence)    rr_intervals_sequences.append(rr_intervals_sequence)    st_intervals_sequences.append(st_intervals_sequence)    st_segments_sequences.append(st_segments_sequence)    age_sequences.append(age)    gender_sequences.append(encoded_gender)    heartrate_sequences.append(heartrate)# Convert the lists of padded sequences to arraysamplitudes_p_in = np.concatenate(amplitudes_p_sequences)amplitudes_q_in = np.concatenate(amplitudes_q_sequences)amplitudes_r_in = np.concatenate(amplitudes_r_sequences)amplitudes_s_in = np.concatenate(amplitudes_s_sequences)amplitudes_t_in = np.concatenate(amplitudes_t_sequences)pr_intervals_in = np.concatenate(pr_intervals_sequences)pr_segments_in = np.concatenate(pr_segments_sequences)qrs_intervals_in = np.concatenate(qrs_intervals_sequences)qt_intervals_in = np.concatenate(qt_intervals_sequences)rr_intervals_in = np.concatenate(rr_intervals_sequences)st_intervals_in = np.concatenate(st_intervals_sequences)st_segments_in = np.concatenate(st_segments_sequences)# Add an extra dimension to the last three featuresheartrate_in = np.array(heartrate_sequences).reshape(-1, 1)  # Shape: (82, 1)age_in = np.array(age_sequences).reshape(-1, 1)  # Shape: (82, 1)gender_in = np.array(gender_sequences).reshape(-1, 1)  # Shape: (82, 1)# Append inputs and labels to their respective listspatient_inputs = [amplitudes_p_in, amplitudes_q_in, amplitudes_r_in, amplitudes_s_in, amplitudes_t_in, pr_intervals_in, pr_segments_in, qrs_intervals_in, qt_intervals_in, rr_intervals_in, st_intervals_in, st_segments_in, heartrate_in, age_in, gender_in]# Tokenize the diagnosis labelstokenizer = Tokenizer(oov_token=None)tokenizer.fit_on_texts(diagnosis)encoded_diagnoses = tokenizer.texts_to_matrix(diagnosis, mode='binary')[:, 1:]diagnosis_class_count = len(tokenizer.word_index)  # Number of unique diagnoses# Split each feature into training and testing setstrain_split = int(0.8 * len(patient_inputs[0]))  # Assuming 82 is the number of rows in your dataX_train = []X_test = []for feature_array in patient_inputs:    # Slice the array to get the training and testing sets    feature_train = feature_array[:train_split]    feature_test = feature_array[train_split:]        X_train.append(feature_train)    X_test.append(feature_test)        y_train = encoded_diagnoses[:train_split]y_test = encoded_diagnoses[train_split:]# Model architecture (as previously defined)num_samples = 5000num_channels = 1# Define input shapesamplitudes_p_input = Input(shape=(None,))amplitudes_q_input = Input(shape=(None,))amplitudes_r_input = Input(shape=(None,))amplitudes_s_input = Input(shape=(None,))amplitudes_t_input = Input(shape=(None,))pr_intervals_input = Input(shape=(None,))pr_segments_input = Input(shape=(None,))qrs_intervals_input = Input(shape=(None,))qt_intervals_input = Input(shape=(None,))rr_intervals_input = Input(shape=(None,))st_intervals_input = Input(shape=(None,))st_segments_input = Input(shape=(None,))heartrate_input = Input(shape=(None,))age_input = Input(shape=(1,))sex_input = Input(shape=(1,))# Combine the featuresamplitudes_input = [amplitudes_p_input, amplitudes_q_input, amplitudes_r_input, amplitudes_s_input, amplitudes_t_input, pr_intervals_input, pr_segments_input, qrs_intervals_input, qt_intervals_input, rr_intervals_input, st_intervals_input, st_segments_input, heartrate_input, age_input, sex_input]amplitudes_features = Add()(amplitudes_input)amplitudes_features_subnetwork = Dense(64, activation='relu')(amplitudes_features)# Additional processing layerscombined = Dense(32, activation='relu')(amplitudes_features_subnetwork)# Output layer for multi-label diagnosis predictiondiagnosis_output = Dense(diagnosis_class_count, activation='sigmoid')(combined)batch_size = 32  # You can set the batch size as needednum_epochs = 10  # Define the number of training epochs# Create the model with multi-label diagnosis outputmodel = Model(inputs=amplitudes_input, outputs=diagnosis_output)model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'f1', 'precision', 'recall'])model.summary()model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=num_epochs, batch_size=batch_size)test_metrics = model.evaluate(X_test, y_test)